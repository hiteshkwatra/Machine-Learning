{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import sklearn.datasets as Datasets\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection as cv\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a function to convert continuos values to discrete values\n",
    "def makeLabelled(column):\n",
    "    mean = column.mean()\n",
    "    for i in range (0,len(column)):\n",
    "        column[i] = int(column[i]>=mean) \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Iris Dataset to change it to Labeled DataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = Datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#As iris dataset has continuous values, we will convert them into discrete nunbers\n",
    "for i in range(0,X.shape[-1]):\n",
    "    X[:,i] = makeLabelled(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dot_data= export_graphviz(clf, out_file=None)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"iris.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function calculates entropy\n",
    "def entropy(Y):\n",
    "    classes = set(Y)\n",
    "    #print(\"Different Classes are = \",classes)\n",
    "    value = 0\n",
    "    for i in classes:\n",
    "        p = (len(Y[Y==i])/len(Y))\n",
    "        value = value - (p*np.log2(p))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finding gain ration for a selected feature\n",
    "def findGainRatio(X,Y,selectedFeature):\n",
    "    differentLabels = set(X[:,selectedFeature])\n",
    "    entropyBeforeSplitting = entropy(Y)\n",
    "    entropyAfterSplitting = 0\n",
    "    splitInfo = 0\n",
    "    \n",
    "    \n",
    "    for i in differentLabels:\n",
    "        newNodeY = Y[(X[:,selectedFeature] == i)]\n",
    "        weightOfSamples = (len(newNodeY)/len(Y))\n",
    "        entropyAfterSplitting = entropyAfterSplitting + (weightOfSamples*entropy(newNodeY))\n",
    "        splitInfo = splitInfo - (weightOfSamples*np.log2(weightOfSamples))\n",
    "        \n",
    "        \n",
    "        \n",
    "    #print(\"Entropy Before Splitting = \",entropyBeforeSplitting)\n",
    "    #print(\"Entropy After Splitting = \",entropyAfterSplitting)\n",
    "    gain = entropyBeforeSplitting - entropyAfterSplitting\n",
    "    gainRatio = gain#/splitInfo\n",
    "    #print(\"gain is = \",gain)\n",
    "    #print(\"split info is = \",splitInfo)\n",
    "    #print(\"gain Ratio is = \",gainRatio)\n",
    "    return gainRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function will count of samples for each class.\n",
    "def printClassification(Y):\n",
    "    classes = set(Y)\n",
    "    for i in classes:\n",
    "        print(\"Count of \",i,\" = \",len(Y[Y==i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to create and print Decision tree. This function prints the selected feature at every step and corresponding entropy.\n",
    "def printSplitsDFS(X,Y,available_features):\n",
    "    print(\" \")\n",
    "    printClassification(Y)\n",
    "    print(\"Current Entropy is = \",entropy(Y))\n",
    "    if(available_features == 0 or (entropy(Y) == 0)):\n",
    "        print(\"Reached leaf Node\")\n",
    "        return\n",
    "    \n",
    "    selectedFeature = 0\n",
    "    max_value = float('-inf')\n",
    "    \n",
    "\n",
    "    \n",
    "    #finding gain ratio for all possible features on which we can split and then choosing the feature with maximum gain.\n",
    "    for i in range(0,X.shape[-1]):\n",
    "        value = findGainRatio(X,Y,i)\n",
    "        print(value)\n",
    "        if(value >= max_value):\n",
    "            selectedFeature = i\n",
    "            max_value = value\n",
    "    print(\"gain ratio =\",value)        \n",
    "    print(\"Splitting on feature \",selectedFeature)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Find all possible unique labels for the selected feature.\n",
    "    differentLabels = set(X[:,selectedFeature])\n",
    "    \n",
    "    for i in differentLabels:\n",
    "       \n",
    "        newx = X[X[:,selectedFeature] == i]\n",
    "        newy = Y[X[:,selectedFeature] == i]\n",
    "        \n",
    "        printSplitsDFS(newx,newy,available_features-1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Count of  0  =  50\n",
      "Count of  1  =  50\n",
      "Count of  2  =  50\n",
      "Current Entropy is =  1.58496250072\n",
      "0.487389498221\n",
      "0.260631095328\n",
      "0.763295751679\n",
      "0.730307896159\n",
      "gain ratio = 0.730307896159\n",
      "Splitting on feature  2\n",
      " \n",
      "Count of  0  =  50\n",
      "Count of  1  =  7\n",
      "Current Entropy is =  0.537376085338\n",
      "0.0\n",
      "0.275062497974\n",
      "0.0\n",
      "0.0547569424928\n",
      "gain ratio = 0.0547569424928\n",
      "Splitting on feature  1\n",
      " \n",
      "Count of  0  =  8\n",
      "Count of  1  =  7\n",
      "Current Entropy is =  0.996791631982\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.077245371683\n",
      "gain ratio = 0.077245371683\n",
      "Splitting on feature  3\n",
      " \n",
      "Count of  0  =  8\n",
      "Count of  1  =  6\n",
      "Current Entropy is =  0.985228136034\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "gain ratio = 0.0\n",
      "Splitting on feature  3\n",
      " \n",
      "Count of  0  =  8\n",
      "Count of  1  =  6\n",
      "Current Entropy is =  0.985228136034\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  0  =  42\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  43\n",
      "Count of  2  =  50\n",
      "Current Entropy is =  0.995909413894\n",
      "0.0747409302576\n",
      "0.0220696492031\n",
      "0.0\n",
      "0.0494924318331\n",
      "gain ratio = 0.0494924318331\n",
      "Splitting on feature  0\n",
      " \n",
      "Count of  1  =  17\n",
      "Count of  2  =  6\n",
      "Current Entropy is =  0.82805572538\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.061715813005\n",
      "gain ratio = 0.061715813005\n",
      "Splitting on feature  3\n",
      " \n",
      "Count of  1  =  3\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  14\n",
      "Count of  2  =  6\n",
      "Current Entropy is =  0.881290899231\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "gain ratio = 0.0\n",
      "Splitting on feature  3\n",
      " \n",
      "Count of  1  =  14\n",
      "Count of  2  =  6\n",
      "Current Entropy is =  0.881290899231\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  26\n",
      "Count of  2  =  44\n",
      "Current Entropy is =  0.951762675635\n",
      "0.0\n",
      "0.00458677286951\n",
      "0.0\n",
      "0.0206656534451\n",
      "gain ratio = 0.0206656534451\n",
      "Splitting on feature  3\n",
      " \n",
      "Count of  1  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  25\n",
      "Count of  2  =  44\n",
      "Current Entropy is =  0.944591181932\n",
      "0.0\n",
      "0.00320427173624\n",
      "0.0\n",
      "0.0\n",
      "gain ratio = 0.0\n",
      "Splitting on feature  1\n",
      " \n",
      "Count of  1  =  17\n",
      "Count of  2  =  27\n",
      "Current Entropy is =  0.962412735463\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  1  =  8\n",
      "Count of  2  =  17\n",
      "Current Entropy is =  0.904381457724\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "printSplitsDFS(X,Y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  3\n",
      "Current Entropy is =  0.811278124459\n",
      "0.311278124459\n",
      "0.311278124459\n",
      "gain ratio = 0.311278124459\n",
      "Splitting on feature  1\n",
      " \n",
      "Count of  1  =  2\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  0  =  1\n",
      "Count of  1  =  1\n",
      "Current Entropy is =  1.0\n",
      "1.0\n",
      "0.0\n",
      "gain ratio = 0.0\n",
      "Splitting on feature  0\n",
      " \n",
      "Count of  1  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n",
      " \n",
      "Count of  0  =  1\n",
      "Current Entropy is =  0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[1,0],[0,1],[1,1]])\n",
    "Y = np.array([1,1,1,0])\n",
    "printSplitsDFS(X,Y,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
